{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“„ article_1.html\n",
      "\n",
      "ðŸ”¹ Unknown (35 blocks):\n",
      "   Your privacy, your choiceWe use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of...\n",
      "\n",
      "ðŸ”¹ Abstract (121 blocks):\n",
      "   Advertisement...\n",
      "\n",
      "ðŸ”¹ References (184 blocks):\n",
      "   Ding Y, John NW, Smith L, Sun JA, Smith M (2015) Combination of 3D skin surface texture features and 2D ABCD features for improved melanoma diagnosis....\n",
      "\n",
      "ðŸ“„ article_2.html\n",
      "\n",
      "ðŸ”¹ Unknown (35 blocks):\n",
      "   Your privacy, your choiceWe use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of...\n",
      "\n",
      "ðŸ”¹ Abstract (82 blocks):\n",
      "   Advertisement...\n",
      "\n",
      "ðŸ”¹ References (139 blocks):\n",
      "   Alam MM, Islam MT (2019) Machine learning approach of automatic identification and counting of blood cells. Healthc Technol Lett 6(4):103â€“108ArticleGo...\n",
      "\n",
      "ðŸ“„ article_3.html\n",
      "\n",
      "ðŸ”¹ Unknown (44 blocks):\n",
      "   Your privacy, your choiceWe use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of...\n",
      "\n",
      "ðŸ”¹ Abstract (158 blocks):\n",
      "   Advertisement...\n",
      "\n",
      "ðŸ”¹ Methods (88 blocks):\n",
      "   This section provides a description of the dataset used in this study, the pre-processing steps for the WBC images, and the proposed CNN-based archite...\n",
      "\n",
      "ðŸ”¹ Results (1 blocks):\n",
      "   (i) W-Net achieves an average accuracy of 97%. In comparison to state-of-the-art methods in the field of WBC classification, we show that W-Net outper...\n",
      "\n",
      "ðŸ”¹ Conclusion (7 blocks):\n",
      "   Analysis of WBC images is essential for diagnosing leukemia. Although there are several methods for detecting and counting WBCs from microscopic image...\n",
      "\n",
      "ðŸ”¹ References (244 blocks):\n",
      "   Changhun J, Mohammed A, Jumabek A, Aziz M, Kyungja H, DaeHun N. W-Net: a CNN-based architecture for white blood cells image classification. In: AAAI 2...\n",
      "\n",
      "ðŸ“„ article_4.html\n",
      "\n",
      "ðŸ”¹ Unknown (35 blocks):\n",
      "   Your privacy, your choiceWe use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of...\n",
      "\n",
      "ðŸ”¹ Abstract (120 blocks):\n",
      "   Advertisement...\n",
      "\n",
      "ðŸ”¹ References (177 blocks):\n",
      "   Liu S, Deng Z, Li J, Wang J, Huang N, Cui R, Zhang Q, Mei J, Zhou W, Zhang C, Ye Q, Tian J (2019) Measurement of the refractive index of whole blood a...\n",
      "\n",
      "ðŸ“„ article_5.html\n",
      "\n",
      "ðŸ”¹ Unknown (34 blocks):\n",
      "   Your privacy, your choiceWe use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of...\n",
      "\n",
      "ðŸ”¹ Abstract (121 blocks):\n",
      "   Advertisement...\n",
      "\n",
      "ðŸ”¹ References (157 blocks):\n",
      "   Abdurrazzaq A, Junoh AK, Yahya Z, Mohd I (2020) New white blood cell detection technique by using singular value decomposition concept. Multimed Tools...\n",
      "\n",
      "ðŸ“„ real_page.html\n",
      "\n",
      "ðŸ”¹ Unknown (163 blocks):\n",
      "   Loading...The system can't perform the operation now. Try again later.CiteAdvanced searchFind articleswithallof the wordswith theexact phrasewithat le...\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import re\n",
    "\n",
    "folder = \"D:\\\\RAM\\\\AI\\\\NLP\\\\REP_gen\\\\pro_1\\\\pdf_analysis\\\\samples_pdf\\\\\"\n",
    "\n",
    "def extract_sections_from_html(file_path):\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        soup = BeautifulSoup(f, \"html.parser\")\n",
    "    \n",
    "    text_blocks = soup.find_all([\"h1\", \"h2\", \"h3\", \"p\", \"div\"])\n",
    "    sections = {}\n",
    "    current_section = \"Unknown\"\n",
    "\n",
    "    for tag in text_blocks:\n",
    "        text = tag.get_text(strip=True)\n",
    "        if not text:\n",
    "            continue\n",
    "\n",
    "        # Match section headers\n",
    "        match = re.match(r\"(abstract|introduction|methods?|results?|discussion|conclusion|references?)\", text.lower())\n",
    "        if match:\n",
    "            current_section = match.group(1).capitalize()\n",
    "            sections[current_section] = []\n",
    "        else:\n",
    "            sections.setdefault(current_section, []).append(text)\n",
    "\n",
    "    return sections\n",
    "\n",
    "# Loop through all HTML files and extract\n",
    "for filename in os.listdir(folder):\n",
    "    if filename.endswith(\".html\"):\n",
    "        path = os.path.join(folder, filename)\n",
    "        print(f\"\\nðŸ“„ {filename}\")\n",
    "        sections = extract_sections_from_html(path)\n",
    "\n",
    "        for section, content in sections.items():\n",
    "            print(f\"\\nðŸ”¹ {section} ({len(content)} blocks):\")\n",
    "            print(\"   \" + content[0][:150] + \"...\")  # Preview first 150 chars of the section\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:4: SyntaxWarning: invalid escape sequence '\\A'\n",
      "<>:4: SyntaxWarning: invalid escape sequence '\\A'\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_11680\\1582623928.py:4: SyntaxWarning: invalid escape sequence '\\A'\n",
      "  file = \"D:\\\\RAM\\AI\\\\NLP\\\\REP_gen\\\\pro_1\\\\pdf_analysis\\\\samples_pdf\\\\real_page.html\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¤– This appears to be a Google Scholar search results page, but the content of the page is not visible due to its lengthy and complex HTML structure.\n",
      "\n",
      "However, based on the structure and layout of the page, it appears that this is a search results page for academic papers related to \"convolutional neural networks\" (CNNs). The page displays a list of 10 research articles or papers that match the search query, along with relevant metadata such as author names, publication dates, and titles.\n",
      "\n",
      "If you'd like to see the actual content of the pages listed on this page, you would need to click on the individual article titles to view their full texts.\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "\n",
    "# Load the .html file directly\n",
    "file = \"D:\\\\RAM\\AI\\\\NLP\\\\REP_gen\\\\pro_1\\\\pdf_analysis\\\\samples_pdf\\\\real_page.html\"\n",
    "with open(file, \"r\", encoding=\"utf-8\") as f:\n",
    "    html_content = f.read()\n",
    "\n",
    "# Initialize a conversation\n",
    "response = ollama.chat(\n",
    "    model=\"llama3.2\",  # Or \"mistral\", \"phi\", etc.\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are an assistant who reads and explains HTML pages.\"},\n",
    "        {\"role\": \"user\", \"content\": f\"Here is the content of a website:\\n\\n{html_content}\\n\\nCan you summarize what this page is about?\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"ðŸ¤–\", response[\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33muser_proxy\u001b[0m (to code_writer):\n",
      "\n",
      "Write a Python function that prints 'Hello, World!'\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mcode_writer\u001b[0m (to user_proxy):\n",
      "\n",
      "Certainly! Here's a simple Python function that prints 'Hello, World!':\n",
      "\n",
      "```python\n",
      "def print_hello_world():\n",
      "    print('Hello, World!')\n",
      "\n",
      "# Call the function\n",
      "print_hello_world()\n",
      "```\n",
      "\n",
      "This function, when called, will output `Hello, World!` to the console. \n",
      "\n",
      "Done\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> TERMINATING RUN (81b2f08d-36a2-4779-9f87-190a2ad6a464): Termination message condition on agent 'user_proxy' met and no human input provided\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ChatResult(chat_id=None, chat_history=[{'content': \"Write a Python function that prints 'Hello, World!'\", 'role': 'assistant', 'name': 'user_proxy'}, {'content': \"Certainly! Here's a simple Python function that prints 'Hello, World!':\\n\\n```python\\ndef print_hello_world():\\n    print('Hello, World!')\\n\\n# Call the function\\nprint_hello_world()\\n```\\n\\nThis function, when called, will output `Hello, World!` to the console. \\n\\nDone\", 'role': 'user', 'name': 'code_writer'}], summary=\"Certainly! Here's a simple Python function that prints 'Hello, World!':\\n\\n```python\\ndef print_hello_world():\\n    print('Hello, World!')\\n\\n# Call the function\\nprint_hello_world()\\n```\\n\\nThis function, when called, will output `Hello, World!` to the console. \\n\\nDone\", cost={'usage_including_cached_inference': {'total_cost': 0.0008425, 'gpt-4o-2024-08-06': {'cost': 0.0008425, 'prompt_tokens': 77, 'completion_tokens': 65, 'total_tokens': 142}}, 'usage_excluding_cached_inference': {'total_cost': 0.0008425, 'gpt-4o-2024-08-06': {'cost': 0.0008425, 'prompt_tokens': 77, 'completion_tokens': 65, 'total_tokens': 142}}}, human_input=['exit'])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from autogen import AssistantAgent, UserProxyAgent, GroupChat, GroupChatManager\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "\n",
    "coder = AssistantAgent(\n",
    "    \"code_writer\",\n",
    "    llm_config={\"config_list\":[{\"model\": \"gpt-4o\",\"api_key\": os.getenv(\"openai_key_2\")}]},\n",
    "    #llm_config={\"config_list\":[{\"model\":\"codegemma\",\"api_key\":\"ollama\", \"base_url\": \"http://localhost:11434\"}]},\n",
    "    human_input_mode=\"NEVER\",\n",
    "    system_message=\"\"\"You are a helpful assistant that can write code in Python\n",
    "    if the user ask some general question ohter than coding, just answer that without use executor in your general knowledge\n",
    "    once done with erply send `Done` also with respon to terminate the chat\"\"\"\n",
    ")\n",
    "\n",
    "executor = UserProxyAgent(\n",
    "    \"user_proxy\",\n",
    "    human_input_mode=\"TERMINATE\",\n",
    "    is_termination_msg=lambda msg : \"Done\" in msg['content'],\n",
    "    default_auto_reply=\"here is the result!!!\",\n",
    "    max_consecutive_auto_reply=2,\n",
    "    #code_execution_config={\"work_dir\": \"code\",\"use_docker\": False},\n",
    ")\n",
    "\n",
    "executor.initiate_chat(coder,message=\"Write a Python function that prints 'Hello, World!'\")\n",
    "#executor.initiate_chat(coder,message=\"what is quantum computing say that in 30 words\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP_ENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
