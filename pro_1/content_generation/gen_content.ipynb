{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“„ article_1.html\n",
      "\n",
      "ðŸ”¹ Unknown (35 blocks):\n",
      "   Your privacy, your choiceWe use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of...\n",
      "\n",
      "ðŸ”¹ Abstract (121 blocks):\n",
      "   Advertisement...\n",
      "\n",
      "ðŸ”¹ References (184 blocks):\n",
      "   Ding Y, John NW, Smith L, Sun JA, Smith M (2015) Combination of 3D skin surface texture features and 2D ABCD features for improved melanoma diagnosis....\n",
      "\n",
      "ðŸ“„ article_2.html\n",
      "\n",
      "ðŸ”¹ Unknown (35 blocks):\n",
      "   Your privacy, your choiceWe use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of...\n",
      "\n",
      "ðŸ”¹ Abstract (82 blocks):\n",
      "   Advertisement...\n",
      "\n",
      "ðŸ”¹ References (139 blocks):\n",
      "   Alam MM, Islam MT (2019) Machine learning approach of automatic identification and counting of blood cells. Healthc Technol Lett 6(4):103â€“108ArticleGo...\n",
      "\n",
      "ðŸ“„ article_3.html\n",
      "\n",
      "ðŸ”¹ Unknown (44 blocks):\n",
      "   Your privacy, your choiceWe use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of...\n",
      "\n",
      "ðŸ”¹ Abstract (158 blocks):\n",
      "   Advertisement...\n",
      "\n",
      "ðŸ”¹ Methods (88 blocks):\n",
      "   This section provides a description of the dataset used in this study, the pre-processing steps for the WBC images, and the proposed CNN-based archite...\n",
      "\n",
      "ðŸ”¹ Results (1 blocks):\n",
      "   (i) W-Net achieves an average accuracy of 97%. In comparison to state-of-the-art methods in the field of WBC classification, we show that W-Net outper...\n",
      "\n",
      "ðŸ”¹ Conclusion (7 blocks):\n",
      "   Analysis of WBC images is essential for diagnosing leukemia. Although there are several methods for detecting and counting WBCs from microscopic image...\n",
      "\n",
      "ðŸ”¹ References (244 blocks):\n",
      "   Changhun J, Mohammed A, Jumabek A, Aziz M, Kyungja H, DaeHun N. W-Net: a CNN-based architecture for white blood cells image classification. In: AAAI 2...\n",
      "\n",
      "ðŸ“„ article_4.html\n",
      "\n",
      "ðŸ”¹ Unknown (35 blocks):\n",
      "   Your privacy, your choiceWe use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of...\n",
      "\n",
      "ðŸ”¹ Abstract (120 blocks):\n",
      "   Advertisement...\n",
      "\n",
      "ðŸ”¹ References (177 blocks):\n",
      "   Liu S, Deng Z, Li J, Wang J, Huang N, Cui R, Zhang Q, Mei J, Zhou W, Zhang C, Ye Q, Tian J (2019) Measurement of the refractive index of whole blood a...\n",
      "\n",
      "ðŸ“„ article_5.html\n",
      "\n",
      "ðŸ”¹ Unknown (34 blocks):\n",
      "   Your privacy, your choiceWe use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of...\n",
      "\n",
      "ðŸ”¹ Abstract (121 blocks):\n",
      "   Advertisement...\n",
      "\n",
      "ðŸ”¹ References (157 blocks):\n",
      "   Abdurrazzaq A, Junoh AK, Yahya Z, Mohd I (2020) New white blood cell detection technique by using singular value decomposition concept. Multimed Tools...\n",
      "\n",
      "ðŸ“„ real_page.html\n",
      "\n",
      "ðŸ”¹ Unknown (163 blocks):\n",
      "   Loading...The system can't perform the operation now. Try again later.CiteAdvanced searchFind articleswithallof the wordswith theexact phrasewithat le...\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import re\n",
    "\n",
    "folder = \"D:\\\\RAM\\\\AI\\\\NLP\\\\REP_gen\\\\pro_1\\\\pdf_analysis\\\\samples_pdf\\\\\"\n",
    "\n",
    "def extract_sections_from_html(file_path):\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        soup = BeautifulSoup(f, \"html.parser\")\n",
    "    \n",
    "    text_blocks = soup.find_all([\"h1\", \"h2\", \"h3\", \"p\", \"div\"])\n",
    "    sections = {}\n",
    "    current_section = \"Unknown\"\n",
    "\n",
    "    for tag in text_blocks:\n",
    "        text = tag.get_text(strip=True)\n",
    "        if not text:\n",
    "            continue\n",
    "\n",
    "        # Match section headers\n",
    "        match = re.match(r\"(abstract|introduction|methods?|results?|discussion|conclusion|references?)\", text.lower())\n",
    "        if match:\n",
    "            current_section = match.group(1).capitalize()\n",
    "            sections[current_section] = []\n",
    "        else:\n",
    "            sections.setdefault(current_section, []).append(text)\n",
    "\n",
    "    return sections\n",
    "\n",
    "# Loop through all HTML files and extract\n",
    "for filename in os.listdir(folder):\n",
    "    if filename.endswith(\".html\"):\n",
    "        path = os.path.join(folder, filename)\n",
    "        print(f\"\\nðŸ“„ {filename}\")\n",
    "        sections = extract_sections_from_html(path)\n",
    "\n",
    "        for section, content in sections.items():\n",
    "            print(f\"\\nðŸ”¹ {section} ({len(content)} blocks):\")\n",
    "            print(\"   \" + content[0][:150] + \"...\")  # Preview first 150 chars of the section\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:4: SyntaxWarning: invalid escape sequence '\\A'\n",
      "<>:4: SyntaxWarning: invalid escape sequence '\\A'\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_11680\\1582623928.py:4: SyntaxWarning: invalid escape sequence '\\A'\n",
      "  file = \"D:\\\\RAM\\AI\\\\NLP\\\\REP_gen\\\\pro_1\\\\pdf_analysis\\\\samples_pdf\\\\real_page.html\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¤– This appears to be a Google Scholar search results page, but the content of the page is not visible due to its lengthy and complex HTML structure.\n",
      "\n",
      "However, based on the structure and layout of the page, it appears that this is a search results page for academic papers related to \"convolutional neural networks\" (CNNs). The page displays a list of 10 research articles or papers that match the search query, along with relevant metadata such as author names, publication dates, and titles.\n",
      "\n",
      "If you'd like to see the actual content of the pages listed on this page, you would need to click on the individual article titles to view their full texts.\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "\n",
    "# Load the .html file directly\n",
    "file = \"D:\\\\RAM\\AI\\\\NLP\\\\REP_gen\\\\pro_1\\\\pdf_analysis\\\\samples_pdf\\\\real_page.html\"\n",
    "with open(file, \"r\", encoding=\"utf-8\") as f:\n",
    "    html_content = f.read()\n",
    "\n",
    "# Initialize a conversation\n",
    "response = ollama.chat(\n",
    "    model=\"llama3.2\",  # Or \"mistral\", \"phi\", etc.\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are an assistant who reads and explains HTML pages.\"},\n",
    "        {\"role\": \"user\", \"content\": f\"Here is the content of a website:\\n\\n{html_content}\\n\\nCan you summarize what this page is about?\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"ðŸ¤–\", response[\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
